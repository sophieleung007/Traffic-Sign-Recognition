{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Efficient traffic sign recognition on low power devices by optimizing YOLOv2 & YOLOv8 (Code)"
      ],
      "metadata": {
        "id": "7g9PtPNxyCr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "TiUDZKzyyT-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP60EsI1kNd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446aa917-1242-4ce0-ed78-5fdcb14729f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'css2-repo'...\n",
            "remote: Enumerating objects: 21732, done.\u001b[K\n",
            "remote: Counting objects: 100% (4537/4537), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3239/3239), done.\u001b[K\n",
            "remote: Total 21732 (delta 504), reused 4536 (delta 504), pack-reused 17195\u001b[K\n",
            "Receiving objects: 100% (21732/21732), 2.08 GiB | 26.19 MiB/s, done.\n",
            "Resolving deltas: 100% (2250/2250), done.\n",
            "Updating files: 100% (19343/19343), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone 'https://github.com/101Viper777/css2-repo'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzQ6_mU0lJkd"
      },
      "source": [
        "## YOLOv8 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMne1GXsjIEd",
        "outputId": "de29d039-5358-409a-b10c-b720408830d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.18-py3-none-any.whl (757 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.2/757.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.18\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOTw6NvEkR1O"
      },
      "outputs": [],
      "source": [
        "filename = \"tdata.yaml\"\n",
        "with open(filename, \"w\") as file:\n",
        "    file.write(\"{\")\n",
        "    file.write(\"names: [prohibitor, danger, mandatory, other], \")\n",
        "    file.write(\"nc: 4, \")\n",
        "    file.write(\"test: /content/css2-repo/ipdata/test, \")\n",
        "    file.write(\"train: /content/css2-repo/ipdata/train, \")\n",
        "    file.write(\"val: /content/css2-repo/ipdata/valid\")\n",
        "    file.write(\"}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqF7PezRkTUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d3ba27-6cdb-4cdb-e333-5a959f333b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 79.2MB/s]\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=tdata.yaml, epochs=33, time=None, patience=100, batch=16, imgsz=480, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 13.4MB/s]\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/css2-repo/ipdata/train... 506 images, 0 backgrounds, 0 corrupt: 100% 506/506 [00:01<00:00, 386.41it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/css2-repo/ipdata/train/00340.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/css2-repo/ipdata/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<00:00, 383.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/css2-repo/ipdata/valid.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 480 train, 480 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 33 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/33      1.46G      1.607      4.463     0.9529         31        480: 100% 32/32 [00:19<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.62it/s]\n",
            "                   all        157        242    0.00194      0.377    0.00135   0.000611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/33       1.4G      1.518      2.857     0.9012         29        480: 100% 32/32 [00:17<00:00,  1.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.11it/s]\n",
            "                   all        157        242      0.479      0.394      0.388      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/33       1.4G      1.392      2.209     0.8743         28        480: 100% 32/32 [00:15<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.26it/s]\n",
            "                   all        157        242      0.734      0.231      0.546      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/33       1.4G      1.356       1.95     0.8682         32        480: 100% 32/32 [00:14<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.35it/s]\n",
            "                   all        157        242      0.824      0.478      0.615      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/33       1.4G      1.335      1.718     0.8653         25        480: 100% 32/32 [00:15<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.65it/s]\n",
            "                   all        157        242      0.836      0.601      0.719       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/33       1.4G      1.301      1.602     0.8626         25        480: 100% 32/32 [00:16<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.53it/s]\n",
            "                   all        157        242      0.888      0.592      0.725       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/33       1.4G      1.237      1.387     0.8612         25        480: 100% 32/32 [00:15<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.25it/s]\n",
            "                   all        157        242      0.911      0.641      0.769      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/33       1.4G      1.238      1.353     0.8533         31        480: 100% 32/32 [00:15<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.30it/s]\n",
            "                   all        157        242      0.883      0.681      0.785      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/33       1.4G      1.138        1.2     0.8463         33        480: 100% 32/32 [00:15<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.50it/s]\n",
            "                   all        157        242      0.886      0.725      0.829      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/33       1.4G      1.111      1.157     0.8346         28        480: 100% 32/32 [00:16<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.19it/s]\n",
            "                   all        157        242      0.899      0.734      0.825      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/33       1.4G      1.114      1.097     0.8403         30        480: 100% 32/32 [00:15<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.40it/s]\n",
            "                   all        157        242      0.905      0.725      0.843      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/33       1.4G      1.115      1.015     0.8432         44        480: 100% 32/32 [00:15<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.30it/s]\n",
            "                   all        157        242      0.963      0.674      0.852      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/33       1.4G      1.102      1.003     0.8322         33        480: 100% 32/32 [00:15<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.03it/s]\n",
            "                   all        157        242      0.914      0.687      0.846      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/33       1.4G      1.067     0.9729     0.8345         36        480: 100% 32/32 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.28it/s]\n",
            "                   all        157        242      0.907      0.735      0.854      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/33       1.4G      1.061     0.9415      0.826         33        480: 100% 32/32 [00:13<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.16it/s]\n",
            "                   all        157        242      0.948      0.755      0.869      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/33       1.4G     0.9774     0.8347     0.8176         24        480: 100% 32/32 [00:12<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.13it/s]\n",
            "                   all        157        242      0.893      0.758      0.843      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/33       1.4G      1.013     0.8417     0.8267         22        480: 100% 32/32 [00:12<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.34it/s]\n",
            "                   all        157        242      0.924      0.758      0.872      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/33       1.4G      1.001     0.8349     0.8236         24        480: 100% 32/32 [00:12<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.23it/s]\n",
            "                   all        157        242      0.943      0.741      0.864      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/33       1.4G     0.9839     0.8027      0.814         35        480: 100% 32/32 [00:12<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.32it/s]\n",
            "                   all        157        242      0.887      0.804       0.87      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/33       1.4G     0.9475     0.7841      0.815         22        480: 100% 32/32 [00:12<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:05<00:00,  1.15s/it]\n",
            "                   all        157        242      0.906      0.807      0.882      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/33       1.4G     0.9187     0.7511     0.8134         32        480: 100% 32/32 [00:16<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.63it/s]\n",
            "                   all        157        242      0.897      0.837      0.882      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/33       1.4G     0.9276     0.7218     0.8276         31        480: 100% 32/32 [00:14<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.47it/s]\n",
            "                   all        157        242      0.923       0.79      0.886      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/33       1.4G       0.95     0.7633     0.8183         24        480: 100% 32/32 [00:13<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.18it/s]\n",
            "                   all        157        242      0.854       0.83      0.872       0.62\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/33      1.41G     0.9443     0.7906     0.8212         15        480: 100% 32/32 [00:18<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.32it/s]\n",
            "                   all        157        242      0.907      0.759      0.867      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/33      1.41G     0.9098     0.7609     0.8159         22        480: 100% 32/32 [00:18<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.16it/s]\n",
            "                   all        157        242      0.882      0.801      0.881       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/33      1.41G     0.8821     0.7378     0.8119         15        480: 100% 32/32 [00:17<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.62it/s]\n",
            "                   all        157        242      0.942      0.832      0.889      0.648\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/33      1.41G     0.8655     0.6998     0.8113         12        480: 100% 32/32 [00:16<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.22it/s]\n",
            "                   all        157        242      0.934      0.838      0.899      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/33      1.41G     0.8153     0.6718     0.8183         16        480: 100% 32/32 [00:16<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.10it/s]\n",
            "                   all        157        242      0.895      0.862      0.897      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/33      1.41G     0.8267     0.6632     0.7954         15        480: 100% 32/32 [00:16<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.25it/s]\n",
            "                   all        157        242      0.928      0.819      0.895      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/33      1.41G     0.8184     0.6475     0.8101         17        480: 100% 32/32 [00:15<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.17it/s]\n",
            "                   all        157        242      0.939       0.82      0.897      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/33      1.41G     0.8014     0.6395     0.8024         19        480: 100% 32/32 [00:16<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.44it/s]\n",
            "                   all        157        242      0.904       0.86      0.903      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/33      1.41G     0.8051     0.6221     0.8028         13        480: 100% 32/32 [00:16<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.30it/s]\n",
            "                   all        157        242      0.914      0.852      0.904      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/33      1.41G     0.7877     0.6297     0.7975         16        480: 100% 32/32 [00:16<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.33it/s]\n",
            "                   all        157        242      0.907      0.866      0.903      0.682\n",
            "\n",
            "33 epochs completed in 0.185 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.17it/s]\n",
            "                   all        157        242      0.917      0.852      0.904      0.685\n",
            "            prohibitor        157        109       0.96      0.872      0.974      0.752\n",
            "                danger        157         34      0.987      0.882      0.902      0.726\n",
            "             mandatory        157         35      0.861      0.887      0.896      0.667\n",
            "                 other        157         64      0.862      0.766      0.844      0.597\n",
            "Speed: 0.2ms preprocess, 4.5ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train model=yolov8n.pt data=tdata.yaml epochs=33 imgsz=480"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show Validation Metrics"
      ],
      "metadata": {
        "id": "-_MXTzhJy4RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')  # load a custom model\n",
        "\n",
        "# Validate the model\n",
        "metrics = model.val()\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category"
      ],
      "metadata": {
        "id": "GbX4QNRoAac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa009420-1f42-43a2-dac8-072ee44d8c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.9 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100%|██████████| 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        157        242      0.977      0.841      0.925      0.752\n",
            "            prohibitor        157        109          1       0.88      0.969      0.814\n",
            "                danger        157         34          1        0.9       0.96      0.806\n",
            "             mandatory        157         35      0.928        0.8      0.897      0.703\n",
            "                 other        157         64       0.98      0.785      0.875      0.684\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 0.0ms loss, 22.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0.81439,     0.80585,     0.70319,     0.68367])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Trained Model to Predict Signs"
      ],
      "metadata": {
        "id": "e6JpZPStx_1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('/content/runs/detect/train/weights/best.pt')  # load a custom model\n",
        "\n",
        "model.predict('/content/css2-repo/ipdata/test/00801.jpg', save=True, imgsz=(480), conf=0.5)\n",
        "model.predict('/content/css2-repo/ipdata/test/00897.jpg', save=True, imgsz=(480), conf=0.5)\n",
        "model.predict('/content/css2-repo/ipdata/test/00835.jpg', save=True, imgsz=(480), conf=0.5)\n",
        "model.predict('/content/css2-repo/ipdata/test/00879.jpg', save=True, imgsz=(480), conf=0.5)"
      ],
      "metadata": {
        "id": "wkXJ8c3WzpI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1ea11d-915c-4a54-debb-7198ae49cefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/css2-repo/ipdata/test/00801.jpg: 288x480 1 mandatory, 107.2ms\n",
            "Speed: 1.9ms preprocess, 107.2ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "\n",
            "image 1/1 /content/css2-repo/ipdata/test/00897.jpg: 288x480 (no detections), 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "\n",
            "image 1/1 /content/css2-repo/ipdata/test/00835.jpg: 288x480 1 other, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "\n",
            "image 1/1 /content/css2-repo/ipdata/test/00879.jpg: 288x480 2 others, 8.3ms\n",
            "Speed: 1.4ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'prohibitor', 1: 'danger', 2: 'mandatory', 3: 'other'}\n",
              " obb: None\n",
              " orig_img: array([[[251, 255, 255],\n",
              "         [250, 253, 251],\n",
              "         [255, 255, 247],\n",
              "         ...,\n",
              "         [255, 255, 252],\n",
              "         [252, 251, 255],\n",
              "         [249, 249, 255]],\n",
              " \n",
              "        [[253, 253, 253],\n",
              "         [255, 255, 251],\n",
              "         [255, 255, 241],\n",
              "         ...,\n",
              "         [255, 255, 242],\n",
              "         [255, 254, 255],\n",
              "         [252, 251, 255]],\n",
              " \n",
              "        [[255, 255, 254],\n",
              "         [255, 255, 247],\n",
              "         [198, 174, 146],\n",
              "         ...,\n",
              "         [210, 191, 153],\n",
              "         [255, 255, 240],\n",
              "         [255, 255, 251]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [251, 255, 255],\n",
              "         [ 17,  25,  24],\n",
              "         ...,\n",
              "         [ 38,  32,  19],\n",
              "         [255, 255, 251],\n",
              "         [253, 255, 254]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [251, 255, 255],\n",
              "         [ 17,  25,  24],\n",
              "         ...,\n",
              "         [ 38,  32,  19],\n",
              "         [255, 255, 251],\n",
              "         [253, 255, 254]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [251, 255, 255],\n",
              "         [ 18,  26,  25],\n",
              "         ...,\n",
              "         [ 38,  32,  19],\n",
              "         [255, 255, 251],\n",
              "         [253, 255, 254]]], dtype=uint8)\n",
              " orig_shape: (800, 1360)\n",
              " path: '/content/css2-repo/ipdata/test/00879.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 1.420736312866211, 'inference': 8.272647857666016, 'postprocess': 1.2562274932861328}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test FPS of Model on the Test Set"
      ],
      "metadata": {
        "id": "msSXqWwezQuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import psutil"
      ],
      "metadata": {
        "id": "kQG_68319sFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt source=/content/css2-repo/ipdata/test data = tdata.yaml\n",
        "inference_time = time.time() - start_time\n",
        "\n",
        "# Get CPU usage at the beginning and end of inference\n",
        "cpu_usage_before = psutil.cpu_percent()\n",
        "cpu_usage_after = psutil.cpu_percent()\n",
        "\n",
        "print(f\"Inference time: {inference_time:.2f} seconds\")\n",
        "print(f\"CPU usage before inference: {cpu_usage_before:.2f}%\")\n",
        "print(f\"CPU usage after inference: {cpu_usage_after:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKGT5z8i1oUc",
        "outputId": "3f0b9a0c-96d6-40e7-c99c-8a6177472412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:09<00:00,  1.03it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.1ms preprocess, 5.0ms inference, 0.0ms loss, 22.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Inference time: 21.77 seconds\n",
            "CPU usage before inference: 57.40%\n",
            "CPU usage after inference: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_usage_before = psutil.virtual_memory().used / (1024 * 1024 * 1024)  # Get memory usage in GB\n",
        "!yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt source=/content/css2-repo/ipdata/test data = tdata.yaml\n",
        "memory_usage_after = psutil.virtual_memory().used / (1024 * 1024 * 1024)\n",
        "print(f\"Memory usage before inference: {memory_usage_before:.2f} GB\")\n",
        "print(f\"Memory usage after inference: {memory_usage_after:.2f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL5YXzuX7aMR",
        "outputId": "cf13f2e7-8ff8-4270-ecf8-b6ab6811f315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:07<00:00,  1.28it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.1ms preprocess, 5.6ms inference, 0.0ms loss, 17.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Memory usage before inference: 0.95 GB\n",
            "Memory usage after inference: 0.93 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rylU58e3FBvD",
        "outputId": "1a2e30cc-c83a-475f-91fa-51754ab4d93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:07<00:00,  1.40it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.9ms preprocess, 5.2ms inference, 0.0ms loss, 17.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val13\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.14it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms loss, 17.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val14\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.18it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.8ms preprocess, 5.1ms inference, 0.0ms loss, 24.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val15\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:07<00:00,  1.33it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.8ms preprocess, 4.8ms inference, 0.0ms loss, 16.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val16\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:06<00:00,  1.47it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.0ms preprocess, 4.2ms inference, 0.1ms loss, 15.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val17\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.18it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.0ms loss, 17.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val18\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.18it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.4ms preprocess, 6.6ms inference, 0.0ms loss, 22.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val19\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.18it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.0ms preprocess, 5.4ms inference, 0.0ms loss, 18.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val20\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:07<00:00,  1.26it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.9ms preprocess, 6.9ms inference, 0.0ms loss, 16.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val21\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.20it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 2.4ms preprocess, 4.9ms inference, 0.0ms loss, 22.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val22\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Average inference time: 17.44 seconds\n",
            "Average CPU usage increase: -76.04%\n",
            "Average memory usage increase: 0.00 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_times = []\n",
        "cpu_usage_before = []\n",
        "cpu_usage_after = []\n",
        "memory_usage_before = []\n",
        "memory_usage_after = []\n",
        "\n",
        "for _ in range(10):  # Run inference 10 times\n",
        "    !yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt source=/content/css2-repo/ipdata/test data = tdata.yaml\n",
        "    inference_times.append(inference_time)\n",
        "    cpu_usage_before.append(cpu_usage_before)\n",
        "\n",
        "\n",
        "# Calculate and print average values\n",
        "average_inference_time = sum(inference_times) / len(inference_times)\n",
        "\n",
        "print(f\"Average inference time: {average_inference_time:.2f} seconds\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8V1WEs77oA6",
        "outputId": "4ccee679-621d-4b6c-af4d-0b85974c139a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:07<00:00,  1.28it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.9ms preprocess, 5.7ms inference, 0.0ms loss, 18.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:09<00:00,  1.08it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 0.0ms loss, 20.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.13it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.0ms preprocess, 5.8ms inference, 0.0ms loss, 17.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.19it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 0.0ms loss, 17.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:09<00:00,  1.10it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 0.0ms loss, 24.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:07<00:00,  1.31it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.9ms preprocess, 4.7ms inference, 0.0ms loss, 17.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val8\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:09<00:00,  1.05it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 0.0ms loss, 19.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val9\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.11it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.7ms preprocess, 5.6ms inference, 0.0ms loss, 16.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val10\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:08<00:00,  1.15it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 0.7ms preprocess, 7.0ms inference, 0.0ms loss, 19.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val11\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/css2-repo/ipdata/valid.cache... 157 images, 0 backgrounds, 0 corrupt: 100% 157/157 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 10/10 [00:09<00:00,  1.08it/s]\n",
            "                   all        157        242      0.919      0.852      0.904      0.689\n",
            "            prohibitor        157        109      0.969      0.872      0.976      0.754\n",
            "                danger        157         34      0.986      0.882      0.902      0.735\n",
            "             mandatory        157         35      0.861      0.888      0.895      0.665\n",
            "                 other        157         64       0.86      0.766      0.844      0.602\n",
            "Speed: 1.0ms preprocess, 4.9ms inference, 0.0ms loss, 20.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val12\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Average inference time: 21.77 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "weights_path = \"/content/runs/detect/train/weights/best.pt\"\n",
        "image_dir = \"/content/css2-repo/ipdata/test\"\n",
        "data_config = \"tdata.yaml\"\n",
        "\n",
        "# Track total prediction time\n",
        "total_time = 0.0\n",
        "\n",
        "# Get a list of image filenames from the test image directory\n",
        "images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "\n",
        "# Loop through images and measure prediction time for each\n",
        "for image in images:\n",
        "  # Construct the YOLOv2 inference command\n",
        "  inference_command = f\"!yolo task=detect mode=val model={weights_path} source={image_dir}/{image} data={data_config}\"\n",
        "\n",
        "  # Start time measurement\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Run the YOLOv2 inference command using subprocess\n",
        "  os.system(inference_command)\n",
        "  # End time measurement\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate prediction time for this image\n",
        "  prediction_time = end_time - start_time\n",
        "  total_time += prediction_time\n",
        "\n",
        "  print(f\"Image: {image}, Prediction time: {prediction_time:.4f} seconds\")\n",
        "\n",
        "# Calculate average prediction time per image\n",
        "average_time_per_image = total_time / len(images)\n",
        "\n",
        "# Calculate estimated frames per second (assuming constant prediction time)\n",
        "fps = 1.0 / average_time_per_image\n",
        "\n",
        "print(f\"Average prediction time per image: {average_time_per_image:.4f} seconds\")\n",
        "print(f\"Estimated frames per second: {fps:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Bqgh72iSjm",
        "outputId": "65806569-9ecd-46ba-a71b-f16e2f380257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 00836.txt, Prediction time: 0.0110 seconds\n",
            "Image: 00825.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00818.jpg, Prediction time: 0.0012 seconds\n",
            "Image: 00857.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00886.jpg, Prediction time: 0.0036 seconds\n",
            "Image: 00894.txt, Prediction time: 0.0052 seconds\n",
            "Image: 00801.txt, Prediction time: 0.0161 seconds\n",
            "Image: 00899.jpg, Prediction time: 0.0198 seconds\n",
            "Image: 00801.jpg, Prediction time: 0.0069 seconds\n",
            "Image: 00893.jpg, Prediction time: 0.0120 seconds\n",
            "Image: 00802.txt, Prediction time: 0.0069 seconds\n",
            "Image: 00864.txt, Prediction time: 0.0158 seconds\n",
            "Image: 00857.jpg, Prediction time: 0.0133 seconds\n",
            "Image: 00816.jpg, Prediction time: 0.0158 seconds\n",
            "Image: 00882.jpg, Prediction time: 0.0099 seconds\n",
            "Image: 00848.jpg, Prediction time: 0.0165 seconds\n",
            "Image: 00888.txt, Prediction time: 0.0124 seconds\n",
            "Image: 00842.txt, Prediction time: 0.0119 seconds\n",
            "Image: 00858.txt, Prediction time: 0.0131 seconds\n",
            "Image: 00809.jpg, Prediction time: 0.0117 seconds\n",
            "Image: 00849.txt, Prediction time: 0.0200 seconds\n",
            "Image: 00834.txt, Prediction time: 0.0056 seconds\n",
            "Image: 00805.txt, Prediction time: 0.0158 seconds\n",
            "Image: 00885.txt, Prediction time: 0.0087 seconds\n",
            "Image: 00807.jpg, Prediction time: 0.0116 seconds\n",
            "Image: 00803.jpg, Prediction time: 0.0186 seconds\n",
            "Image: 00809.txt, Prediction time: 0.0152 seconds\n",
            "Image: 00865.jpg, Prediction time: 0.0183 seconds\n",
            "Image: 00897.jpg, Prediction time: 0.0127 seconds\n",
            "Image: 00805.jpg, Prediction time: 0.0044 seconds\n",
            "Image: 00860.jpg, Prediction time: 0.0172 seconds\n",
            "Image: 00891.txt, Prediction time: 0.0110 seconds\n",
            "Image: 00835.txt, Prediction time: 0.0060 seconds\n",
            "Image: 00872.txt, Prediction time: 0.0069 seconds\n",
            "Image: 00850.jpg, Prediction time: 0.0047 seconds\n",
            "Image: 00871.jpg, Prediction time: 0.0040 seconds\n",
            "Image: 00854.txt, Prediction time: 0.0038 seconds\n",
            "Image: 00817.jpg, Prediction time: 0.0048 seconds\n",
            "Image: 00882.txt, Prediction time: 0.0059 seconds\n",
            "Image: 00863.txt, Prediction time: 0.0019 seconds\n",
            "Image: 00811.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00827.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00813.jpg, Prediction time: 0.0022 seconds\n",
            "Image: 00855.txt, Prediction time: 0.0014 seconds\n",
            "Image: 00824.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00831.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00899.txt, Prediction time: 0.0033 seconds\n",
            "Image: 00823.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00859.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00829.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00876.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00884.jpg, Prediction time: 0.0051 seconds\n",
            "Image: 00820.txt, Prediction time: 0.0018 seconds\n",
            "Image: 00895.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00821.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00886.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00806.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00823.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00867.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00834.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00842.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00881.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00808.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00827.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00897.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00817.txt, Prediction time: 0.0018 seconds\n",
            "Image: 00879.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00846.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00874.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00852.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00851.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00862.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00848.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00869.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00864.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00859.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00837.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00869.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00810.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00876.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00845.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00802.jpg, Prediction time: 0.0018 seconds\n",
            "Image: 00885.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00858.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00808.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00831.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00896.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00838.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00855.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00887.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00837.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00870.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00884.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00894.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00853.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00833.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00824.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00821.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00863.jpg, Prediction time: 0.0070 seconds\n",
            "Image: 00852.jpg, Prediction time: 0.0078 seconds\n",
            "Image: 00806.jpg, Prediction time: 0.0070 seconds\n",
            "Image: 00844.txt, Prediction time: 0.0050 seconds\n",
            "Image: 00828.txt, Prediction time: 0.0058 seconds\n",
            "Image: 00816.txt, Prediction time: 0.0202 seconds\n",
            "Image: 00822.txt, Prediction time: 0.0018 seconds\n",
            "Image: 00839.txt, Prediction time: 0.0128 seconds\n",
            "Image: 00851.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00846.jpg, Prediction time: 0.0046 seconds\n",
            "Image: 00822.jpg, Prediction time: 0.0131 seconds\n",
            "Image: 00839.jpg, Prediction time: 0.0084 seconds\n",
            "Image: 00889.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00874.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00836.jpg, Prediction time: 0.0035 seconds\n",
            "Image: 00871.txt, Prediction time: 0.0087 seconds\n",
            "Image: 00825.jpg, Prediction time: 0.0018 seconds\n",
            "Image: 00803.txt, Prediction time: 0.0104 seconds\n",
            "Image: 00849.jpg, Prediction time: 0.0158 seconds\n",
            "Image: 00896.txt, Prediction time: 0.0074 seconds\n",
            "Image: 00866.jpg, Prediction time: 0.0064 seconds\n",
            "Image: 00844.jpg, Prediction time: 0.0064 seconds\n",
            "Image: 00818.txt, Prediction time: 0.0021 seconds\n",
            "Image: 00853.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00811.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00810.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00850.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00891.jpg, Prediction time: 0.0023 seconds\n",
            "Image: 00872.jpg, Prediction time: 0.0018 seconds\n",
            "Image: 00813.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00868.jpg, Prediction time: 0.0017 seconds\n",
            "Image: 00838.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00829.txt, Prediction time: 0.0049 seconds\n",
            "Image: 00835.jpg, Prediction time: 0.0014 seconds\n",
            "Image: 00889.txt, Prediction time: 0.0018 seconds\n",
            "Image: 00898.txt, Prediction time: 0.0015 seconds\n",
            "Image: .DS_Store, Prediction time: 0.0017 seconds\n",
            "Image: 00881.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00820.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00898.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00870.txt, Prediction time: 0.0020 seconds\n",
            "Image: 00868.txt, Prediction time: 0.0013 seconds\n",
            "Image: 00887.txt, Prediction time: 0.0014 seconds\n",
            "Image: 00854.jpg, Prediction time: 0.0014 seconds\n",
            "Image: 00807.txt, Prediction time: 0.0021 seconds\n",
            "Image: 00893.txt, Prediction time: 0.0013 seconds\n",
            "Image: 00866.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00860.txt, Prediction time: 0.0014 seconds\n",
            "Image: 00879.jpg, Prediction time: 0.0024 seconds\n",
            "Image: 00828.jpg, Prediction time: 0.0015 seconds\n",
            "Image: 00841.jpg, Prediction time: 0.0014 seconds\n",
            "Image: 00888.jpg, Prediction time: 0.0016 seconds\n",
            "Image: 00867.jpg, Prediction time: 0.0013 seconds\n",
            "Image: 00895.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00845.txt, Prediction time: 0.0015 seconds\n",
            "Image: 00833.txt, Prediction time: 0.0016 seconds\n",
            "Image: 00865.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00862.txt, Prediction time: 0.0017 seconds\n",
            "Image: 00841.txt, Prediction time: 0.0015 seconds\n",
            "Average prediction time per image: 0.0046 seconds\n",
            "Estimated frames per second: 216.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Model Metrics"
      ],
      "metadata": {
        "id": "hRNUiwi7zjtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/runs/modelOutput', 'zip', '/content/runs/detect')"
      ],
      "metadata": {
        "id": "9fLZF3n1oQpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46b3a61d-2e31-4a0e-c03c-42e2434a01ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/runs/modelOutput.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/runs/modelOutput.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YxFqj8gW6he-",
        "outputId": "aed78b15-fbb1-4711-886a-6277e00f9fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5133633a-f55e-4392-a88b-7ed9ee102363\", \"modelOutput.zip\", 21571430)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvUzs1HslNWp"
      },
      "source": [
        "## Yolov2 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjZF9SwPmpbH"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjbipKqGmzMv"
      },
      "outputs": [],
      "source": [
        "cd darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhsoqvk5m0IJ"
      },
      "outputs": [],
      "source": [
        "# Path where to create the config file\n",
        "file_path = '/content/darknet/cfg/yolov2-custom.cfg'\n",
        "\n",
        "# Configuration content\n",
        "config_content = \"\"\"\n",
        "[net]\n",
        "# Testing\n",
        "# batch=1\n",
        "# subdivisions=1\n",
        "# Training\n",
        "batch=128\n",
        "subdivisions=8\n",
        "width=416\n",
        "height=416\n",
        "channels=3\n",
        "momentum=0.9\n",
        "decay=0.0005\n",
        "angle=5\n",
        "saturation=1.5\n",
        "exposure=1.5\n",
        "hue=.1\n",
        "random=1\n",
        "\n",
        "learning_rate=0.001\n",
        "burn_in=1000\n",
        "max_batches=800000\n",
        "policy=adam\n",
        "steps=640000,720000\n",
        "scales=.1,.1\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=1024\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=1024\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=1024\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "\n",
        "#######\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-9\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters=64\n",
        "activation=leaky\n",
        "\n",
        "[reorg]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers=-1,-4\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters=45\n",
        "activation=linear\n",
        "\n",
        "[region]\n",
        "anchors = 0.21841867,0.37079545, 0.31050506,0.52373826, 0.42081879,0.70738527, 0.60991615,1.02093333, 0.97792877,1.59983871\n",
        "bias_match=1\n",
        "classes=4\n",
        "coords=4\n",
        "num=5\n",
        "softmax=1\n",
        "jitter=.3\n",
        "rescore=1\n",
        "\n",
        "object_scale=5\n",
        "noobject_scale=1\n",
        "class_scale=1\n",
        "coord_scale=1\n",
        "\n",
        "absolute=1\n",
        "thresh = .6\n",
        "random=1\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Writing to file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(config_content)\n",
        "\n",
        "print(f\"Configuration file written to {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqKAmBZlm1RK"
      },
      "outputs": [],
      "source": [
        "# Open the Makefile in edit mode\n",
        "with open('/content/darknet/Makefile', 'r+') as file:\n",
        "    # Read the existing content\n",
        "    contents = file.read()\n",
        "\n",
        "    # Replace the lines with the new values\n",
        "    contents = contents.replace('CUDNN=0', 'CUDNN=1')\n",
        "    contents = contents.replace('CUDNN_HALF=0', 'CUDNN_HALF=1')\n",
        "    contents = contents.replace('OPENCV=0', 'OPENCV=1')\n",
        "    contents = contents.replace('GPU=0', 'GPU=1')\n",
        "\n",
        "    # Write the updated content back to the file\n",
        "    file.seek(0)\n",
        "    file.write(contents)\n",
        "    file.truncate()\n",
        "\n",
        "print(\"Makefile updated successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "got2UasMm2Ye"
      },
      "outputs": [],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZGjVpwXquDi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Set the paths\n",
        "data_dir = '/content/css2-repo/ipdata'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'valid')\n",
        "output_dir = '/content/darknet/data'\n",
        "\n",
        "# Define the class names\n",
        "class_names = ['prohibitory', 'danger', 'mandatory', 'other']\n",
        "\n",
        "# Create the obj.data file\n",
        "with open(os.path.join(output_dir, 'obj.data'), 'w') as f:\n",
        "    f.write(f'classes = {len(class_names)}\\n')\n",
        "    f.write(f'train = {os.path.join(output_dir, \"train.txt\")}\\n')\n",
        "    f.write(f'valid = {os.path.join(output_dir, \"val.txt\")}\\n')\n",
        "    f.write(f'names = {os.path.join(output_dir, \"obj.names\")}\\n')\n",
        "    f.write(f'backup = {os.path.join(output_dir, \"backup\")}\\n')\n",
        "    f.write(f'class_weights=1.0,2.5,2.0,1.5 \\n')\n",
        "\n",
        "# Create the obj.names file\n",
        "with open(os.path.join(output_dir, 'obj.names'), 'w') as f:\n",
        "    for name in class_names:\n",
        "        f.write(f'{name}\\n')\n",
        "\n",
        "# Create the train.txt file\n",
        "with open(os.path.join(output_dir, 'train.txt'), 'w') as f:\n",
        "    for filename in os.listdir(train_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            file_path = os.path.join(train_dir, filename)\n",
        "            f.write(f'{file_path}\\n')\n",
        "\n",
        "# Create the val.txt file\n",
        "with open(os.path.join(output_dir, 'val.txt'), 'w') as f:\n",
        "    for filename in os.listdir(val_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            file_path = os.path.join(val_dir, filename)\n",
        "            f.write(f'{file_path}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CisAml48sXGM"
      },
      "outputs": [],
      "source": [
        "!wget https://pjreddie.com/media/files/yolov2.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5DIrxOEynp5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def resize_image(image, target_size):\n",
        "    height, width = image.shape[:2]\n",
        "    new_width = target_size[0]\n",
        "    new_height = target_size[1]\n",
        "    resized_image = cv2.resize(image, (new_width, new_height))\n",
        "    return resized_image, new_width, new_height\n",
        "\n",
        "def update_bounding_box(txt_file, original_size, new_size):\n",
        "    original_width, original_height = original_size\n",
        "    new_width, new_height = new_size\n",
        "    with open(txt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    updated_lines = []\n",
        "    for line in lines:\n",
        "        data = line.strip().split()\n",
        "        class_id = data[0]\n",
        "        x_center = float(data[1])\n",
        "        y_center = float(data[2])\n",
        "        width = float(data[3])\n",
        "        height = float(data[4])\n",
        "        new_x_center = (x_center * original_width) * (new_width / original_width) / new_width\n",
        "        new_y_center = (y_center * original_height) * (new_height / original_height) / new_height\n",
        "        new_width = (width * original_width) * (new_width / original_width) / new_width\n",
        "        new_height = (height * original_height) * (new_height / original_height) / new_height\n",
        "        updated_line = f\"{class_id} {new_x_center:.6f} {new_y_center:.6f} {new_width:.6f} {new_height:.6f}\\n\"\n",
        "        updated_lines.append(updated_line)\n",
        "    with open(txt_file, 'w') as file:\n",
        "        file.writelines(updated_lines)\n",
        "\n",
        "def process_folder(folder_path, target_size, original_size):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "            resized_image, new_width, new_height = resize_image(image, target_size)\n",
        "            cv2.imwrite(image_path, resized_image)\n",
        "            txt_file = os.path.splitext(image_path)[0] + '.txt'\n",
        "            update_bounding_box(txt_file, original_size, (new_width, new_height))\n",
        "\n",
        "# Set the target size (divisible by 32) and original size\n",
        "target_size = (416, 416)  # Adjust the dimensions as needed\n",
        "original_size = (1360, 800)\n",
        "\n",
        "# Process images and bounding boxes in the train folder\n",
        "train_folder = '/content/css2-repo/ipdata/train'\n",
        "process_folder(train_folder, target_size, original_size)\n",
        "\n",
        "# Process images and bounding boxes in the test folder\n",
        "test_folder = '/content/css2-repo/ipdata/test'\n",
        "process_folder(test_folder, target_size, original_size)\n",
        "\n",
        "# Process images and bounding boxes in the val folder\n",
        "val_folder = '/content/css2-repo/ipdata/valid/'\n",
        "process_folder(val_folder, target_size, original_size)\n",
        "\n",
        "print(\"Image resizing and bounding box updating completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_images_per_class(folder_paths):\n",
        "    class_counts = {}\n",
        "    for folder_path in folder_paths:\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith('.txt'):\n",
        "                txt_path = os.path.join(folder_path, filename)\n",
        "                with open(txt_path, 'r') as file:\n",
        "                    lines = file.readlines()\n",
        "                    for line in lines:\n",
        "                        data = line.strip().split()\n",
        "                        class_id = int(data[0])\n",
        "                        class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
        "\n",
        "    for class_id, count in class_counts.items():\n",
        "        print(f\"Class {class_id}: {count} images\")\n",
        "\n",
        "# Specify the paths to your dataset folders\n",
        "dataset_folders = ['/content/css2-repo/ipdata/train', '/content/css2-repo/ipdata/test', '/content/css2-repo/ipdata/valid']\n",
        "\n",
        "# Call the function with the list of folder paths\n",
        "count_images_per_class(dataset_folders)"
      ],
      "metadata": {
        "id": "bemAm-QvQza2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mitH8oNezCFf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def visualize_bounding_boxes(folder_path):\n",
        "    count = 0  # Initialize a counter to track the number of images processed\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            if count >= 3:  # Check if 3 images have already been processed\n",
        "                break  # If yes, stop processing further images in this folder\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            txt_path = os.path.join(folder_path, filename.split('.')[0] + '.txt')\n",
        "\n",
        "            image = cv2.imread(image_path)\n",
        "            height, width, _ = image.shape\n",
        "\n",
        "            with open(txt_path, 'r') as file:\n",
        "                lines = file.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                data = line.strip().split()\n",
        "                class_id = int(data[0])\n",
        "                x_center = float(data[1])\n",
        "                y_center = float(data[2])\n",
        "                bbox_width = float(data[3])\n",
        "                bbox_height = float(data[4])\n",
        "\n",
        "                # Calculate bounding box coordinates\n",
        "                x_min = int((x_center - bbox_width / 2) * width)\n",
        "                y_min = int((y_center - bbox_height / 2) * height)\n",
        "                x_max = int((x_center + bbox_width / 2) * width)\n",
        "                y_max = int((y_center + bbox_height / 2) * height)\n",
        "\n",
        "                # Draw bounding box on the image\n",
        "                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "                print(f\"Image: {filename}\")\n",
        "                print(f\"Bounding Box: ({x_min}, {y_min}), ({x_max}, {y_max})\")\n",
        "                cv2_imshow(image)\n",
        "            count += 1  # Increment the counter after each image\n",
        "\n",
        "            # cv2.waitKey(0)\n",
        "            # cv2.destroyAllWindows()\n",
        "            if cv2.waitKey(0) & 0xFF == 27:  # 27 is the ASCII code for the ESC key\n",
        "                cv2.destroyAllWindows()\n",
        "                break  # Break the loop or return to exit the function early\n",
        "\n",
        "# Call the function for each folder\n",
        "visualize_bounding_boxes('/content/css2-repo/ipdata/train')\n",
        "visualize_bounding_boxes('/content/css2-repo/ipdata/test')\n",
        "visualize_bounding_boxes('/content/css2-repo/ipdata/valid')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://pjreddie.com/media/files/darknet19_448.conv.23\n"
      ],
      "metadata": {
        "id": "RfxxgEdFSfBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector train /content/darknet/data/obj.data /content/darknet/cfg/yolov2-custom.cfg /content/darknet/darknet19_448.conv.23 -map\n"
      ],
      "metadata": {
        "id": "0XRw4qcKW2YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector train /content/darknet/data/obj.data /content/darknet/cfg/yolov2-custom.cfg /content/darknet/darknet19_448.conv.23 -map\n"
      ],
      "metadata": {
        "id": "JxTsIBsUSUpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector valid /content/darknet/data/obj.data /content/darknet/cfg/yolov2-custom.cfg /content/darknet/data/backup/yolov2-custom_best.weights\n",
        "\n"
      ],
      "metadata": {
        "id": "Tkzp4E6pYIsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSGhcnYA7Zsm"
      },
      "source": [
        "## getting anchor for ourt dataset to update the model\n",
        "\n",
        "replaced the\n",
        "\n",
        "line\n",
        "centroid_sums=np.zeros((k,dim), np.float)\n",
        "with\n",
        "centroid_sums=np.zeros((k,dim), float)\n",
        "because of new numpy package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpdLJGjL5UKT"
      },
      "outputs": [],
      "source": [
        "!python gen_anchors.py -filelist /content/darknet/data/train.txt -output_dir /content -num_clusters 5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pvUzs1HslNWp",
        "CSGhcnYA7Zsm"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}